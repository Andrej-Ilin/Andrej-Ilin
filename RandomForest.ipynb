{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1fECYdsYussU6jr1yo8w-Z06XbDYR2B76",
      "authorship_tag": "ABX9TyNgSV2iwRUR1ogsxkCulSko"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y7yQmzP0FqQ"
      },
      "source": [
        "# АЛГОРИТМ ПОСТРОЕНИЯ СЛУЧАЙНОГО ЛЕСА, СОСТОЯЩЕГО ИЗ ДЕРЕВЬЕВ\n",
        "\n",
        "Для каждого:\n",
        "\n",
        "сгенерировать выборку с помощью бутстрэпа;\n",
        "построить решающее дерево по выборке: по заданному критерию мы выбираем лучший признак, делаем разбиение в дереве по нему и так до исчерпания выборки → дерево строится, пока в каждом листе не более объектов или пока не достигнем определенной высоты дерева → при каждом разбиении сначала выбирается несколько случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них.\n",
        "Таким образом, случайный лес — это бэггинг над решающими деревьями, при обучении которых для каждого разбиения признаки выбираются из некоторого случайного подмножества признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdG59ftW3YqQ"
      },
      "source": [
        "## РЕАЛИЗАЦИЯ НА PYTHON  И ПОДБОР ПАРАМЕТРОВ\n",
        "____\n",
        "Теперь обучим случайный лес на простых данных и посмотрим, как можно подбирать параметры случайного леса для достижения наилучшего качества модели.\n",
        "\n",
        "Потренируемся на данных, по которым мы будем предсказывать погоду. Датасет можно найти [здесь](https://lms.skillfactory.ru/assets/courseware/v1/ecd07340ed6b98d6fb556b3429156eb4/asset-v1:Skillfactory+DST-PRO+15APR2020+type@asset+block/temps_extended.csv).\n",
        "\n",
        "Откроем его, удалим признаки, не относящиеся к предсказанию (от дня недели, например, или от года погода не зависит), разделим на тестовую и обучающуюся выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc621FSXzyWC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH25l1avz87_"
      },
      "source": [
        "weather = pd.read_csv('/content/drive/MyDrive/all_data/temps_extended.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyPJnEoi4V-E"
      },
      "source": [
        "y = weather['actual']\n",
        "X = weather.drop(['actual','weekday','month','day','year'],axis =1)\n",
        "X_train, X_val, Y_train, Y_val=train_test_split(X,y,test_size=0.3, random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxww9RE74vHm"
      },
      "source": [
        "Попробуем подобрать гиперпараметры таким образом, чтобы получить оптимальный результат.\n",
        "\n",
        "Если мы запускаем случайный лес без настройки параметров, то по умолчанию они следующие:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQp0XL8U4vzu",
        "outputId": "ca8aca11-4cf5-4c99-c0cb-28c6a7da2bac"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from pprint import pprint\n",
        "rf = RandomForestRegressor(random_state = 42)\n",
        "# Look at parameters used by our current forest\n",
        "print('Параметры по умолчанию:\\n')\n",
        "pprint(rf.get_params())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Параметры по умолчанию:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'criterion': 'mse',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 42,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3izqwzyh5AeO"
      },
      "source": [
        "Попробуем подбирать разные значения для некоторых параметров. Для перебора вариантов возьмем следующие параметры:\n",
        "\n",
        "* n_estimators \n",
        "* max_features \n",
        "* max_depth \n",
        "* min_samples_split \n",
        "* min_samples_leaf\n",
        "* bootstrap\n",
        "\n",
        "Мы можем сами указать, какие значения гиперпараметров надо перебрать.\n",
        "\n",
        "Зададим сетку гиперпараметров, которые будут перебираться:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpnFG6Hd4_5m"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpaKe03v5nyb",
        "outputId": "9e4ffbc2-0d82-436c-ef59-98ec8d4e8627"
      },
      "source": [
        "# Обучим наш лес:\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, \n",
        "                               cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "rf_random.fit(X_train, Y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 12.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                   ccp_alpha=0.0,\n",
              "                                                   criterion='mse',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features='auto',\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=100,\n",
              "                                                   n_jobs=None, oob_score=Fals...\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
              "                                                      70, 80, 90, 100, 110,\n",
              "                                                      None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [200, 400, 600, 800,\n",
              "                                                         1000, 1200, 1400, 1600,\n",
              "                                                         1800, 2000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM2SoWDG5xSm",
        "outputId": "6dc7d40b-2149-4c7c-c64b-4bb93f1d599c"
      },
      "source": [
        "# посмотрим, какие гиперпараметры нам предлагают как оптимальные:\n",
        "rf_random.best_params_"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 10,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 1000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZCU8G8z6Xfq"
      },
      "source": [
        "Обучите случайный лес с предустановленными параметрами и теми параметрами, которые мы отобрали как оптимальные. В обоих вариантах поставьте random_state =42. Какое улучшение MSE дала подстановка отобранных гиперпараметров? Ответ округлите до одного знака после запятой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cV4Bd_S6Ybi"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6MJVEhkCPdl",
        "outputId": "723f32b8-f626-4122-8c15-18800f3201a3"
      },
      "source": [
        "rf.fit(X_train, Y_train)\n",
        "y_pred = rf.predict(X_val)\n",
        "mean_squared_error(Y_val, y_pred)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24.570648328267477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCCvBAA5Ckpu",
        "outputId": "04120ed3-52bd-4424-ad21-78381839d31c"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=42, max_depth=10, max_features='sqrt', min_samples_leaf=2, min_samples_split=5, n_estimators=1000)\n",
        "rf.fit(X_train, Y_train)\n",
        "y_pred = rf.predict(X_val)\n",
        "mean_squared_error(Y_val, y_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.10053911088241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ0piIsiEDzC",
        "outputId": "a4692c7c-e308-4def-fc52-7c228366c178"
      },
      "source": [
        "24.570648328267477 - 23.10053911088241"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.470109217385069"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}