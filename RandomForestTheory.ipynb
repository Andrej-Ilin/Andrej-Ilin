{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForestTheory.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1fECYdsYussU6jr1yo8w-Z06XbDYR2B76",
      "authorship_tag": "ABX9TyOc7CRZ/nWC+6RYqioFoKXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrej-Ilin/Andrej-Ilin/blob/main/RandomForestTheory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y7yQmzP0FqQ"
      },
      "source": [
        "# АЛГОРИТМ ПОСТРОЕНИЯ СЛУЧАЙНОГО ЛЕСА, СОСТОЯЩЕГО ИЗ ДЕРЕВЬЕВ\n",
        "\n",
        "Для каждого:\n",
        "\n",
        "сгенерировать выборку с помощью бутстрэпа;\n",
        "построить решающее дерево по выборке: по заданному критерию мы выбираем лучший признак, делаем разбиение в дереве по нему и так до исчерпания выборки → дерево строится, пока в каждом листе не более объектов или пока не достигнем определенной высоты дерева → при каждом разбиении сначала выбирается несколько случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них.\n",
        "Таким образом, случайный лес — это бэггинг над решающими деревьями, при обучении которых для каждого разбиения признаки выбираются из некоторого случайного подмножества признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdG59ftW3YqQ"
      },
      "source": [
        "## РЕАЛИЗАЦИЯ НА PYTHON  И ПОДБОР ПАРАМЕТРОВ\n",
        "____\n",
        "Теперь обучим случайный лес на простых данных и посмотрим, как можно подбирать параметры случайного леса для достижения наилучшего качества модели.\n",
        "\n",
        "Потренируемся на данных, по которым мы будем предсказывать погоду. Датасет можно найти [здесь](https://lms.skillfactory.ru/assets/courseware/v1/ecd07340ed6b98d6fb556b3429156eb4/asset-v1:Skillfactory+DST-PRO+15APR2020+type@asset+block/temps_extended.csv).\n",
        "\n",
        "Откроем его, удалим признаки, не относящиеся к предсказанию (от дня недели, например, или от года погода не зависит), разделим на тестовую и обучающуюся выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc621FSXzyWC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH25l1avz87_"
      },
      "source": [
        "weather = pd.read_csv('/content/drive/MyDrive/all_data/temps_extended.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyPJnEoi4V-E"
      },
      "source": [
        "y = weather['actual']\n",
        "X = weather.drop(['actual','weekday','month','day','year'],axis =1)\n",
        "X_train, X_val, Y_train, Y_val=train_test_split(X,y,test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxww9RE74vHm"
      },
      "source": [
        "Попробуем подобрать гиперпараметры таким образом, чтобы получить оптимальный результат.\n",
        "\n",
        "Если мы запускаем случайный лес без настройки параметров, то по умолчанию они следующие:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQp0XL8U4vzu",
        "outputId": "d1547da7-2d2e-4acf-fa93-eaf267fef693"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from pprint import pprint\n",
        "rf = RandomForestRegressor(random_state = 42)\n",
        "# Look at parameters used by our current forest\n",
        "print('Параметры по умолчанию:\\n')\n",
        "pprint(rf.get_params())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Параметры по умолчанию:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'criterion': 'mse',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 42,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3izqwzyh5AeO"
      },
      "source": [
        "Попробуем подбирать разные значения для некоторых параметров. Для перебора вариантов возьмем следующие параметры:\n",
        "\n",
        "* n_estimators \n",
        "* max_features \n",
        "* max_depth \n",
        "* min_samples_split \n",
        "* min_samples_leaf\n",
        "* bootstrap\n",
        "\n",
        "Мы можем сами указать, какие значения гиперпараметров надо перебрать.\n",
        "\n",
        "Зададим сетку гиперпараметров, которые будут перебираться:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpnFG6Hd4_5m"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpaKe03v5nyb",
        "outputId": "8c9d1dc4-98e5-40d6-ced4-a5d4d3578998"
      },
      "source": [
        "# Обучим наш лес:\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, \n",
        "                               cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "rf_random.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 12.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                   ccp_alpha=0.0,\n",
              "                                                   criterion='mse',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features='auto',\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=100,\n",
              "                                                   n_jobs=None, oob_score=Fals...\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
              "                                                      70, 80, 90, 100, 110,\n",
              "                                                      None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [200, 400, 600, 800,\n",
              "                                                         1000, 1200, 1400, 1600,\n",
              "                                                         1800, 2000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM2SoWDG5xSm",
        "outputId": "1d3862f9-53de-422a-c97e-e9b2ba355c1b"
      },
      "source": [
        "# посмотрим, какие гиперпараметры нам предлагают как оптимальные:\n",
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 10,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 1000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZCU8G8z6Xfq"
      },
      "source": [
        "Обучите случайный лес с предустановленными параметрами и теми параметрами, которые мы отобрали как оптимальные. В обоих вариантах поставьте random_state =42. Какое улучшение MSE дала подстановка отобранных гиперпараметров? Ответ округлите до одного знака после запятой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cV4Bd_S6Ybi"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6MJVEhkCPdl",
        "outputId": "2126b1c5-dfd7-4440-98f6-edc92059c515"
      },
      "source": [
        "rf.fit(X_train, Y_train)\n",
        "y_pred = rf.predict(X_val)\n",
        "mean_squared_error(Y_val, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24.570648328267477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCCvBAA5Ckpu",
        "outputId": "0a4b094c-fe26-4914-e5a4-ab1a7144b8d3"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=42, max_depth=10, max_features='sqrt', min_samples_leaf=2, min_samples_split=5, n_estimators=1000)\n",
        "rf.fit(X_train, Y_train)\n",
        "y_pred = rf.predict(X_val)\n",
        "mean_squared_error(Y_val, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.10053911088241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Dy4SiUfKN9"
      },
      "source": [
        "## Разберёмся с ансамблями алгоритмов и со случайным лесом. Рассмотрим данные о сотрудниках компании, где указывается, ушёл сотрудник или нет.\n",
        "____\n",
        "[Ссылка на датасет](https://lms.skillfactory.ru/assets/courseware/v1/8dd3362700988d469792f2aa7a5fdcc4/asset-v1:Skillfactory+DST-PRO+15APR2020+type@asset+block/HR-dataset.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqa3r9_fmAs"
      },
      "source": [
        "Сделаем базовую предобработку данных: удалим признак, который отвечает за идентификатор пользователя как нерепрезетативный признак."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zBdV53PfRQR",
        "outputId": "1215d830-4e19-4fca-8c75-7d3a1e774683"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df = pd.read_csv('/content/drive/MyDrive/all_data/HR-dataset.csv')\n",
        "\n",
        "np.random.seed(42)\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "target = 'left'\n",
        "features = df.columns.drop(target)\n",
        "features = features.drop('empid')  # Удалим идентификатор пользователя как нерепрезентативный признак\n",
        "print(features)\n",
        "\n",
        "X, y = df[features].copy(), df[target]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
            "       'average_montly_hours', 'time_spend_company', 'Work_accident',\n",
            "       'promotion_last_5years', 'dept', 'salary'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkI84L7ZjOvu"
      },
      "source": [
        "Заменим идентификатор отдела, к которому относился сотрудник, на количество людей в отделе, а зарплату — на ординальную категорию. Масштабируем признаки для последующего сравнения результатов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLL_2EvjjPQl"
      },
      "source": [
        "salary_ordinals = {'low': 1, 'medium': 2, 'high': 3}\n",
        "\n",
        "X['dept'] = X['dept'].apply(X['dept'].value_counts().get)\n",
        "X['salary'] = X['salary'].apply(salary_ordinals.get)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKFzxWdtjq3I"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGqRFAlhjvNX"
      },
      "source": [
        "В  дальнейшем будем оценивать качество модели на кросс-валидации на пяти фолдах при помощи точности (*accuracy*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diVa28L2j3Rd"
      },
      "source": [
        "def estimate_accuracy(clf, X, y, cv=5):\n",
        "    return cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD-UkPawkHFL"
      },
      "source": [
        "Посмотрим на то, как работает бэггинг над решающими деревьями.\n",
        "___\n",
        "**Бэггинг** (bagging, сокр. от bootstrap aggregating)  — метод построения композиции алгоритмов, в котором каждый алгоритм строится независимо от других на подвыборках обучающей выборки. Итоговый алгоритм принимает решения посредством голосования среди всех алгоритмов (возвращается самый частый ответ)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz49EgP3kPn-",
        "outputId": "e6e5f7e9-cf3a-4094-d512-8c8d049ebf2d"
      },
      "source": [
        "# Посмотрим на точность одного дерева.\n",
        "tree = DecisionTreeClassifier(max_depth=30)\n",
        "print(\"Decision tree:\", estimate_accuracy(tree, X, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision tree: 0.9747313771257085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvkahqZ9kH5y",
        "outputId": "d5bd6667-db7f-43c1-8d33-beb01e92a8a1"
      },
      "source": [
        "# Проведём бэггинг: для этого достаточно обернуть исходный классификатор в BaggingClassifier.\n",
        "bagging_trees = BaggingClassifier(tree)\n",
        "print(\"Decision tree bagging:\", estimate_accuracy(bagging_trees, X, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision tree bagging: 0.9881994664888296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4yfZBMlMsp"
      },
      "source": [
        "**Вывод:**\n",
        "композиция отдельных деревьев показывает себя лучше, чем одно дерево. Структура дерева серьёзно зависит от обучающей выборки. Это значит, что если немного изменить обучающую выборку, то дерево сильно изменится. Бэггинг идеально подходит в этом случае, поскольку композиция алгоритмов при помощи голосования работает наилучшим образом, когда модели различны."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVhNWkWll5MX",
        "outputId": "74849596-6b7d-494d-cb04-57e88b19b619"
      },
      "source": [
        "\"\"\"Увеличить различность построенных деревьев можно, указав параметры \n",
        "max_features и max_depth.\"\"\"\n",
        "\"\"\"Стандартная эвристика: в задаче классификации брать квадратный корень числа\n",
        " признаков, а в задаче регрессии — треть числа признаков.\"\"\"\n",
        "random_tree = DecisionTreeClassifier(max_features=int(np.sqrt(len(features))), max_depth=30) \n",
        "print(\"Random tree:\", estimate_accuracy(random_tree, X, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random tree: 0.97766564410359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktDI9PNil-FW",
        "outputId": "f86c0a3d-9543-4228-a0e9-0709ed2387c7"
      },
      "source": [
        "bagging_random_trees = BaggingClassifier(random_tree)\n",
        "print(\"Random tree bagging:\", estimate_accuracy(bagging_random_trees, X, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random tree bagging: 0.9908662220740247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLGvyM1_n1uu",
        "outputId": "7946dd7c-6c93-4c61-d35b-e0793bf05bae"
      },
      "source": [
        "random_forest = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    max_features=int(np.sqrt(len(features))),\n",
        "    max_depth=30)\n",
        "print(\"Random Forest:\", estimate_accuracy(random_forest, X, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest: 0.9919329776592198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vp7CuE2oYY7"
      },
      "source": [
        "Ещё одно преимущество использования бэггинга для аггрегации моделей — получение оценки работы классификатора без дополнительного проведения кросс-валидации при помощи out-of-bag score. Это метод вычисления произвольной оценки качества во время обучения бэггинга. Для подсчёта требуется указать параметр oob_score = True, что имеет смысл при достаточном количестве деревьев."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnXxCM8PoWlk",
        "outputId": "5f4b3639-5356-44d3-e54d-7451e84a6ffd"
      },
      "source": [
        "random_forest = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_features=int(np.sqrt(len(features))),\n",
        "    max_depth=30,\n",
        "    oob_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "random_forest.fit(X, y)\n",
        "random_forest.oob_score_.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.993132875525035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}